{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97d4c18-98bd-43e9-b49a-874890444aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c186a96-e7a4-4072-83dd-15c4e07bb013",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "data_lst = ['Set5', 'Set14', 'BSD100']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5789b36-1d23-4dcb-af97-eeb1ab84413f",
   "metadata": {},
   "source": [
    "# **ABPN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9074309-1b87-449b-8d3a-5384a5bc8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Attention.ABPN.dataset import *\n",
    "from Attention.ABPN.model import *\n",
    "from Attention.ABPN.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddce7533-a79d-47b3-bb42-7dd80e08770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = 4\n",
    "\n",
    "ori = ABPN_v5(input_dim=3, dim=32)\n",
    "ori.load_state_dict(torch.load('./Attention/ABPN/Models/ABPNv5_X4.pt'))\n",
    "ori = ori.to(device)\n",
    "\n",
    "modi = ABPNv5_LaUD(input_dim=3, dim=48)\n",
    "modi.load_state_dict(torch.load('./Attention/ABPN/Models/ABPNv5_LaUD_X4.pt'))\n",
    "modi = modi.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54916c04-794b-4ea9-ac98-5f231a126256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[For Set5 X4, PSNR and SSIM]\n",
      " ABPN: 32.28 dB and 0.8955\n",
      " ABPN_LaUD: 32.60 dB and 0.8991\n",
      "\n",
      "[For Set14 X4, PSNR and SSIM]\n",
      " ABPN: 28.67 dB and 0.7828\n",
      " ABPN_LaUD: 28.90 dB and 0.7882\n",
      "\n",
      "[For BSD100 X4, PSNR and SSIM]\n",
      " ABPN: 27.61 dB and 0.7379\n",
      " ABPN_LaUD: 27.76 dB and 0.7433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for testdata in data_lst:\n",
    "    testset = test_dataset(root_path='./datasets/for_test', type=testdata,\n",
    "                           is_resize=False, resize_h=None, resize_w=None, is_rcrop=False, crop_h=None, crop_w=None, scale=mag, \n",
    "                           is_rrot=False, rand_hori_flip=False, rand_vert_flip=False, grayscale=False, norm=False)\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    ori.eval()\n",
    "    modi.eval()\n",
    "    with torch.no_grad():\n",
    "        ori_psnr_sum = 0 \n",
    "        ori_ssim_sum = 0\n",
    "        modi_psnr_sum = 0 \n",
    "        modi_ssim_sum = 0\n",
    "        for iteration, data in enumerate(testloader):\n",
    "            hr_img, lr_img = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            sr_ori = ori(lr_img)\n",
    "            sr_modi, det_modi = modi(lr_img)\n",
    "\n",
    "            ori_psnr_sum += cal_psnr(hr_img, sr_ori, crop_border=mag, minmax='0_1', clamp=True, gray_scale=True, ver='YCrCb_BT601')\n",
    "            ori_ssim_sum += cal_ssim(hr_img, sr_ori, crop_border=0, minmax='0_1', filter_size=11, filter_sigma=1.5, clamp=True, grayscale=True, ver='YCrCb_BT601')\n",
    "            \n",
    "            modi_psnr_sum += cal_psnr(hr_img, sr_modi, crop_border=mag, minmax='0_1', clamp=True, gray_scale=True, ver='YCrCb_BT601')\n",
    "            modi_ssim_sum += cal_ssim(hr_img, sr_modi, crop_border=0, minmax='0_1', filter_size=11, filter_sigma=1.5, clamp=True, grayscale=True, ver='YCrCb_BT601')\n",
    "\n",
    "        print('[For {} X{}, PSNR and SSIM]\\n ABPN: {:.2f} dB and {:.4f}\\n ABPN_LaUD: {:.2f} dB and {:.4f}\\n'.format(testdata, mag, ori_psnr_sum/len(testloader), ori_ssim_sum/len(testloader),\n",
    "                                                                                                 modi_psnr_sum/len(testloader), modi_ssim_sum/len(testloader)))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c42ad4-c718-437d-a994-b4a3b682f9dc",
   "metadata": {},
   "source": [
    "# **DRLN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf2d07e-19f6-42fe-9ff7-93062cfa1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Attention.DRLN.dataset import *\n",
    "from Attention.DRLN.model import *\n",
    "from Attention.DRLN.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e30c80-923c-4187-8fda-304929bb2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = 2\n",
    "\n",
    "ori = DRLN(scale=mag)\n",
    "ori.load_state_dict(torch.load('./Attention/DRLN/Models/DRLN_X2.pt'))\n",
    "ori = ori.to(device)\n",
    "\n",
    "modi = DRLN_LaUD(scale=mag)\n",
    "modi.load_state_dict(torch.load('./Attention/DRLN/Models/DRLN_LaUD_X2.pt'))\n",
    "modi = modi.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177296f2-a91d-42f7-9e82-049de0ac29af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[For Set5 X2, PSNR and SSIM]\n",
      " DRLN: 38.10 dB and 0.9610\n",
      " DRLN_LaUD: 38.35 dB and 0.9623\n",
      "\n",
      "[For Set14 X2, PSNR and SSIM]\n",
      " DRLN: 33.75 dB and 0.9188\n",
      " DRLN_LaUD: 34.49 dB and 0.9241\n",
      "\n",
      "[For BSD100 X2, PSNR and SSIM]\n",
      " DRLN: 32.24 dB and 0.9006\n",
      " DRLN_LaUD: 32.49 dB and 0.9039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for testdata in data_lst:\n",
    "    testset = test_dataset(root_path='./datasets/for_test', type=testdata,\n",
    "                           is_resize=False, resize_h=None, resize_w=None, is_rcrop=False, crop_h=None, crop_w=None, scale=mag, \n",
    "                           is_rrot=False, rand_hori_flip=False, rand_vert_flip=False, grayscale=False, norm=False)\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    ori.eval()\n",
    "    modi.eval()\n",
    "    with torch.no_grad():\n",
    "        ori_psnr_sum = 0 \n",
    "        ori_ssim_sum = 0\n",
    "        modi_psnr_sum = 0 \n",
    "        modi_ssim_sum = 0\n",
    "        for iteration, data in enumerate(testloader):\n",
    "            hr_img, lr_img = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            sr_ori = ori(lr_img)\n",
    "            sr_lst_modi, det_lst_modi = modi(lr_img)\n",
    "\n",
    "            ori_psnr_sum += cal_psnr(hr_img, sr_ori, crop_border=mag, minmax='0_1', clamp=True, gray_scale=True, ver='YCrCb_BT601')\n",
    "            ori_ssim_sum += cal_ssim(hr_img, sr_ori, crop_border=0, minmax='0_1', filter_size=11, filter_sigma=1.5, clamp=True, grayscale=True, ver='YCrCb_BT601')\n",
    "            \n",
    "            modi_psnr_sum += cal_psnr(hr_img, sr_lst_modi[-1], crop_border=mag, minmax='0_1', clamp=True, gray_scale=True, ver='YCrCb_BT601')\n",
    "            modi_ssim_sum += cal_ssim(hr_img, sr_lst_modi[-1], crop_border=0, minmax='0_1', filter_size=11, filter_sigma=1.5, clamp=True, grayscale=True, ver='YCrCb_BT601')\n",
    "\n",
    "        print('[For {} X{}, PSNR and SSIM]\\n DRLN: {:.2f} dB and {:.4f}\\n DRLN_LaUD: {:.2f} dB and {:.4f}\\n'.format(testdata, mag, ori_psnr_sum/len(testloader), ori_ssim_sum/len(testloader),\n",
    "                                                                                                 modi_psnr_sum/len(testloader), modi_ssim_sum/len(testloader)))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a4dc5-aeef-49b9-812a-0e905e433803",
   "metadata": {},
   "source": [
    "# **HAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581bd803-6ff3-4271-8d9d-9accf27b4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Attention.HAN.dataset import *\n",
    "from Attention.HAN.model import *\n",
    "from Attention.HAN.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90a56df-c75c-4637-821b-b6df08d26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = 2\n",
    "\n",
    "ori = HAN(reduction=16, scale=mag)\n",
    "ori.load_state_dict(torch.load('./Attention/HAN/Models/HAN_X2.pt'))\n",
    "ori = ori.to(device)\n",
    "\n",
    "modi = HAN_LaUD(reduction=16, scale=mag)\n",
    "modi.load_state_dict(torch.load('./Attention/HAN/Models/HAN_LaUD_X2.pt'))\n",
    "modi = modi.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ecced19-377b-4653-81a9-c96bdec27e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[For Set5 X2, PSNR and SSIM]\n",
      " HAN: 38.26 dB and 0.9616\n",
      " HAN_LaUD: 38.31 dB and 0.9617\n",
      "\n",
      "[For Set14 X2, PSNR and SSIM]\n",
      " HAN: 34.11 dB and 0.9217\n",
      " HAN_LaUD: 34.15 dB and 0.9220\n",
      "\n",
      "[For BSD100 X2, PSNR and SSIM]\n",
      " HAN: 32.39 dB and 0.9027\n",
      " HAN_LaUD: 32.41 dB and 0.9030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for testdata in data_lst:\n",
    "    testset = test_dataset(root_path='./datasets/for_test', type=testdata,\n",
    "                           is_resize=False, resize_h=None, resize_w=None, is_rcrop=False, crop_h=None, crop_w=None, scale=mag, \n",
    "                           is_rrot=False, rand_hori_flip=False, rand_vert_flip=False, grayscale=False)\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    ori.eval()\n",
    "    modi.eval()\n",
    "    with torch.no_grad():\n",
    "        ori_psnr_sum = 0 \n",
    "        ori_ssim_sum = 0\n",
    "        modi_psnr_sum = 0 \n",
    "        modi_ssim_sum = 0\n",
    "        for iteration, data in enumerate(testloader):\n",
    "            hr_img, lr_img = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            sr_ori = ori(lr_img)\n",
    "            sr_modi, det_modi = modi(lr_img)\n",
    "\n",
    "            ori_psnr_sum += cal_psnr(hr_img, sr_ori, crop_border=mag, minmax='0_255', clamp=True, gray_scale=True, ver='YCrCb_BT601')\n",
    "            ori_ssim_sum += cal_ssim(hr_img, sr_ori, crop_border=0, minmax='0_255', filter_size=11, filter_sigma=1.5, clamp=True, grayscale=True, ver='YCrCb_BT601')\n",
    "            \n",
    "            modi_psnr_sum += cal_psnr(hr_img, sr_modi, crop_border=mag, minmax='0_255', clamp=True, gray_scale=True, ver='YCrCb_BT601')\n",
    "            modi_ssim_sum += cal_ssim(hr_img, sr_modi, crop_border=0, minmax='0_255', filter_size=11, filter_sigma=1.5, clamp=True, grayscale=True, ver='YCrCb_BT601')\n",
    "\n",
    "        print('[For {} X{}, PSNR and SSIM]\\n HAN: {:.2f} dB and {:.4f}\\n HAN_LaUD: {:.2f} dB and {:.4f}\\n'.format(testdata, mag, ori_psnr_sum/len(testloader), ori_ssim_sum/len(testloader),\n",
    "                                                                                                 modi_psnr_sum/len(testloader), modi_ssim_sum/len(testloader)))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285b462-550c-4989-8408-22820911b1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0678456-166b-419a-9ec2-567f8f18c67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc788f-63a2-4727-b9f9-fbbb0a5a88ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20136b08-c9bf-4a9a-9bb6-e59244a32d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
